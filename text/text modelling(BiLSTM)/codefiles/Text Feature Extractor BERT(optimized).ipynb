{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f05acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MultimodalDataset'>\n",
      "Done data loading\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "from sklearn.utils import resample\n",
    "import openl3\n",
    "\n",
    "train=pd.read_csv(\"C:/Users/Administrator/Desktop/Text Modelling/DAIC_train_3sp_sampled.csv\")\n",
    "test=pd.read_csv(\"C:/Users/Administrator/Desktop/Text Modelling/DAIC_test_3sp.csv\")\n",
    "torch.manual_seed(101)\n",
    "\n",
    "class TextFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def extract_features(self, texts):\n",
    "        # Tokenize input texts\n",
    "        tokenized_texts = self.tokenizer.batch_encode_plus(\n",
    "            texts,\n",
    "            padding='max_length',\n",
    "            #padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Move tensors to the appropriate device\n",
    "        input_ids = tokenized_texts['input_ids'].to(self.device)\n",
    "        attention_mask = tokenized_texts['attention_mask'].to(self.device)\n",
    "        #print(input_ids.shape)\n",
    "        # Extract text features from BERT model\n",
    "        #with torch.no_grad():\n",
    "            #outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "            #print(type(outputs))\n",
    "           #text_features = outputs[0][:, 0, :].cpu().numpy()  # Use the [CLS] token embedding\n",
    "        #print(\"Text feat dim:\"+str(text_features))\n",
    "        return input_ids\n",
    "\n",
    "    \n",
    "class MultimodalDataset(Dataset):\n",
    "        def __init__(self, data_fr, transform_text=None):\n",
    "            self.data_fr = data_fr\n",
    "            self.transform_text = transform_text\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data_fr)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "        #print(audio_file)\n",
    "            text_p =  self.data_fr.loc[index, \"text\"]\n",
    "            class_id = self.data_fr.loc[index, \"Group\"]\n",
    "        #audio_file = self.audio_files[index]\n",
    "        #text = self.texts[index]\n",
    "\n",
    "\n",
    "        # Extract text features\n",
    "            text_features = self.transform_text.extract_features([text_p])[0]\n",
    "\n",
    "            return text_features, class_id\n",
    "\n",
    "    \n",
    "    \n",
    "batch_size = 32\n",
    "\n",
    "# Initialize feature extractor\n",
    "\n",
    "text_feature_extractor = TextFeatureExtractor()\n",
    "# Create dataset\n",
    "dataset_tr = MultimodalDataset(train, transform_text=text_feature_extractor)\n",
    "dataset_ts = MultimodalDataset(test, transform_text=text_feature_extractor)\n",
    "\n",
    "# Create dataloader\n",
    "tr_dataloader = DataLoader(dataset_tr, batch_size=batch_size, shuffle=True)\n",
    "ts_dataloader = DataLoader(dataset_ts, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Done data loading\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55899239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "[INFO] Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [05:25<00:00,  1.01s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:33<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.05      0.09      1349\n",
      "           1       0.29      0.95      0.45       565\n",
      "\n",
      "    accuracy                           0.31      1914\n",
      "   macro avg       0.49      0.50      0.27      1914\n",
      "weighted avg       0.57      0.31      0.20      1914\n",
      "\n",
      "Train loss: 0.6967, Train accuracy:  0.5207\n",
      "Validation loss: 0.8198, Validation accuracy:  0.3135\n",
      "[INFO] Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [06:01<00:00,  1.12s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:30<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.11      0.19      1349\n",
      "           1       0.30      0.90      0.45       565\n",
      "\n",
      "    accuracy                           0.34      1914\n",
      "   macro avg       0.51      0.51      0.32      1914\n",
      "weighted avg       0.60      0.34      0.27      1914\n",
      "\n",
      "Train loss: 0.6938, Train accuracy:  0.5204\n",
      "Validation loss: 0.7806, Validation accuracy:  0.3443\n",
      "[INFO] Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [04:21<00:00,  1.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:32<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      1349\n",
      "           1       0.28      0.24      0.26       565\n",
      "\n",
      "    accuracy                           0.59      1914\n",
      "   macro avg       0.49      0.49      0.49      1914\n",
      "weighted avg       0.58      0.59      0.58      1914\n",
      "\n",
      "Train loss: 0.6949, Train accuracy:  0.5225\n",
      "Validation loss: 0.6790, Validation accuracy:  0.5930\n",
      "[INFO] Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [04:34<00:00,  1.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:33<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      1349\n",
      "           1       0.67      0.00      0.01       565\n",
      "\n",
      "    accuracy                           0.71      1914\n",
      "   macro avg       0.69      0.50      0.42      1914\n",
      "weighted avg       0.69      0.71      0.58      1914\n",
      "\n",
      "Train loss: 0.6951, Train accuracy:  0.5223\n",
      "Validation loss: 0.6312, Validation accuracy:  0.7053\n",
      "[INFO] Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [03:56<00:00,  1.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:21<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73      1349\n",
      "           1       0.33      0.30      0.31       565\n",
      "\n",
      "    accuracy                           0.62      1914\n",
      "   macro avg       0.52      0.52      0.52      1914\n",
      "weighted avg       0.60      0.62      0.61      1914\n",
      "\n",
      "Train loss: 0.6960, Train accuracy:  0.5200\n",
      "Validation loss: 0.6762, Validation accuracy:  0.6155\n",
      "[INFO] Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [03:06<00:00,  1.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:22<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.80      1349\n",
      "           1       0.33      0.08      0.13       565\n",
      "\n",
      "    accuracy                           0.68      1914\n",
      "   macro avg       0.52      0.51      0.47      1914\n",
      "weighted avg       0.59      0.68      0.61      1914\n",
      "\n",
      "Train loss: 0.6941, Train accuracy:  0.5254\n",
      "Validation loss: 0.6712, Validation accuracy:  0.6782\n",
      "[INFO] Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [03:12<00:00,  1.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:29<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.16      0.26      1349\n",
      "           1       0.29      0.82      0.43       565\n",
      "\n",
      "    accuracy                           0.36      1914\n",
      "   macro avg       0.49      0.49      0.35      1914\n",
      "weighted avg       0.57      0.36      0.31      1914\n",
      "\n",
      "Train loss: 0.6946, Train accuracy:  0.5160\n",
      "Validation loss: 0.7272, Validation accuracy:  0.3574\n",
      "[INFO] Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [04:43<00:00,  1.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:33<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.99      0.82      1349\n",
      "           1       0.26      0.01      0.02       565\n",
      "\n",
      "    accuracy                           0.70      1914\n",
      "   macro avg       0.48      0.50      0.42      1914\n",
      "weighted avg       0.57      0.70      0.59      1914\n",
      "\n",
      "Train loss: 0.6954, Train accuracy:  0.5220\n",
      "Validation loss: 0.6569, Validation accuracy:  0.6980\n",
      "[INFO] Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [05:25<00:00,  1.01s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:33<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.54      1349\n",
      "           1       0.30      0.57      0.39       565\n",
      "\n",
      "    accuracy                           0.47      1914\n",
      "   macro avg       0.50      0.50      0.46      1914\n",
      "weighted avg       0.58      0.47      0.49      1914\n",
      "\n",
      "Train loss: 0.6942, Train accuracy:  0.5213\n",
      "Validation loss: 0.6874, Validation accuracy:  0.4728\n",
      "[INFO] Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [04:43<00:00,  1.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:35<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.06      0.12      1349\n",
      "           1       0.29      0.93      0.45       565\n",
      "\n",
      "    accuracy                           0.32      1914\n",
      "   macro avg       0.49      0.50      0.28      1914\n",
      "weighted avg       0.57      0.32      0.21      1914\n",
      "\n",
      "Train loss: 0.6931, Train accuracy:  0.5257\n",
      "Validation loss: 0.7525, Validation accuracy:  0.3197\n",
      "[INFO] Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [03:23<00:00,  1.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:21<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.05      0.09      1349\n",
      "           1       0.29      0.94      0.45       565\n",
      "\n",
      "    accuracy                           0.31      1914\n",
      "   macro avg       0.47      0.49      0.27      1914\n",
      "weighted avg       0.55      0.31      0.20      1914\n",
      "\n",
      "Train loss: 0.6947, Train accuracy:  0.5159\n",
      "Validation loss: 0.7782, Validation accuracy:  0.3114\n",
      "[INFO] Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [03:58<00:00,  1.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:26<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.19      0.30      1349\n",
      "           1       0.29      0.79      0.42       565\n",
      "\n",
      "    accuracy                           0.37      1914\n",
      "   macro avg       0.49      0.49      0.36      1914\n",
      "weighted avg       0.57      0.37      0.34      1914\n",
      "\n",
      "Train loss: 0.6915, Train accuracy:  0.5284\n",
      "Validation loss: 0.7107, Validation accuracy:  0.3694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "    \n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        #print(\"After\")\n",
    "        #print(x.shape)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1])\n",
    "        return out\n",
    "\n",
    "class AccuracyMetric:\n",
    "    def __init__(self):\n",
    "        self.correct, self.total = None, None\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, y_pred, y_true):\n",
    "        self.correct += torch.sum(y_pred.argmax(-1) == y_true).item()\n",
    "        self.total += y_true.size(0)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct / self.total\n",
    "\n",
    "    def reset(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0    \n",
    "\n",
    "# Set the hyperparameters\n",
    "#input_size = embeddings.shape[1]\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "model = LSTMClassifier(512, hidden_size, num_classes)\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "next(model.parameters()).device\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "epochs = 12\n",
    "\n",
    "# training loop\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "valid_loss_history = []\n",
    "valid_accuracy_history = []\n",
    "\n",
    "accuracy = AccuracyMetric()\n",
    "best_acc=0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"[INFO] Epoch: {epoch}\")\n",
    "    model.train()\n",
    "\n",
    "    batch_train_loss = []\n",
    "    batch_valid_loss = []\n",
    "\n",
    "    predicted_label=[]\n",
    "\n",
    "    true_label=[]\n",
    "    \n",
    "    for osfeat, y_batch in tqdm(tr_dataloader):\n",
    "        # perform single training step\n",
    "        #print(X_batch.shape)\n",
    "        #print(osfeat.shape)\n",
    "        model.zero_grad()\n",
    "        #print(\"Before\")\n",
    "        \n",
    "        osfeat, y_batch = osfeat.to(device), y_batch.to(device)\n",
    "        y_predicted = model(osfeat.float())\n",
    "        #print(\"After Model call\")\n",
    "        loss = criterion(y_predicted, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accuracy.update(y_predicted, y_batch)\n",
    "        batch_train_loss.append(loss.item())\n",
    "\n",
    "    mean_epoch_loss_train = np.mean(batch_train_loss)\n",
    "    train_accuracy = accuracy.compute()\n",
    "\n",
    "    train_loss_history.append(mean_epoch_loss_train)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    accuracy.reset()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for osfeat, y_batch in tqdm(ts_dataloader):\n",
    "            #print(X_batch.shape)\n",
    "            true_label+=list(y_batch.tolist())\n",
    "            osfeat, y_batch = osfeat.to(device), y_batch.to(device)\n",
    "\n",
    "            y_predicted = model(osfeat.float())\n",
    "            #print(y_predicted)\n",
    "            loss_val = criterion(y_predicted, y_batch)\n",
    "            predicted_label+=y_predicted.argmax(-1).tolist()\n",
    "            accuracy.update(y_predicted, y_batch)\n",
    "            batch_valid_loss.append(loss_val.item())\n",
    "\n",
    "    mean_epoch_loss_valid = np.mean(batch_valid_loss)\n",
    "    valid_accuracy = accuracy.compute()\n",
    "\n",
    "    if valid_accuracy > best_acc:\n",
    "        best_acc=valid_accuracy\n",
    "        model_depression_text_LSTM_best_bert = torch.jit.script(model)\n",
    "        model_depression_text_LSTM_best_bert.save('model_depression_text_LSTM_best_bert.pt')\n",
    "        \n",
    "\n",
    "\n",
    "    valid_loss_history.append(mean_epoch_loss_valid)\n",
    "    valid_accuracy_history.append(valid_accuracy)\n",
    "    accuracy.reset()\n",
    "    print(classification_report(true_label, predicted_label))\n",
    "    print(\n",
    "        f\"Train loss: {mean_epoch_loss_train:0.4f}, Train accuracy: {train_accuracy: 0.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Validation loss: {mean_epoch_loss_valid:0.4f}, Validation accuracy: {valid_accuracy: 0.4f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
